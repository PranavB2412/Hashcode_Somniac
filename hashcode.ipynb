{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Bedtime</th>\n",
       "      <th>Wakeup_time</th>\n",
       "      <th>Sleep_duration</th>\n",
       "      <th>Sleep_efficiency</th>\n",
       "      <th>REM_sleep_percentage</th>\n",
       "      <th>Deep_sleep_percentage</th>\n",
       "      <th>Light_sleep_percentage</th>\n",
       "      <th>Awakenings</th>\n",
       "      <th>Caffeine_consumption</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Exercise_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>06-03-2021 01:00</td>\n",
       "      <td>06-03-2021 07:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>05-12-2021 02:00</td>\n",
       "      <td>05-12-2021 09:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>25-05-2021 21:30</td>\n",
       "      <td>25-05-2021 05:30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>03-11-2021 02:30</td>\n",
       "      <td>03-11-2021 08:30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>13-03-2021 01:00</td>\n",
       "      <td>13-03-2021 09:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>446</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>16-11-2021 23:00</td>\n",
       "      <td>16-11-2021 06:30</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>448</td>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>13-11-2021 22:00</td>\n",
       "      <td>13-11-2021 05:30</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>449</td>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>31-03-2021 21:00</td>\n",
       "      <td>31-03-2021 03:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>451</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>29-07-2021 21:00</td>\n",
       "      <td>29-07-2021 04:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>452</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>17-03-2021 02:30</td>\n",
       "      <td>17-03-2021 10:00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.63</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Age  Gender           Bedtime       Wakeup_time  Sleep_duration   \\\n",
       "0      1   65  Female  06-03-2021 01:00  06-03-2021 07:00              6.0   \n",
       "1      2   69    Male  05-12-2021 02:00  05-12-2021 09:00              7.0   \n",
       "2      3   40  Female  25-05-2021 21:30  25-05-2021 05:30              8.0   \n",
       "3      4   40  Female  03-11-2021 02:30  03-11-2021 08:30              6.0   \n",
       "4      5   57    Male  13-03-2021 01:00  13-03-2021 09:00              8.0   \n",
       "..   ...  ...     ...               ...               ...              ...   \n",
       "445  446   30  Female  16-11-2021 23:00  16-11-2021 06:30              7.5   \n",
       "447  448   27  Female  13-11-2021 22:00  13-11-2021 05:30              7.5   \n",
       "448  449   52    Male  31-03-2021 21:00  31-03-2021 03:00              6.0   \n",
       "450  451   45    Male  29-07-2021 21:00  29-07-2021 04:00              7.0   \n",
       "451  452   18    Male  17-03-2021 02:30  17-03-2021 10:00              7.5   \n",
       "\n",
       "     Sleep_efficiency  REM_sleep_percentage  Deep_sleep_percentage  \\\n",
       "0                0.88                    18                     70   \n",
       "1                0.66                    19                     28   \n",
       "2                0.89                    20                     70   \n",
       "3                0.51                    23                     25   \n",
       "4                0.76                    27                     55   \n",
       "..                ...                   ...                    ...   \n",
       "445              0.53                    28                     20   \n",
       "447              0.91                    22                     57   \n",
       "448              0.74                    28                     57   \n",
       "450              0.76                    18                     72   \n",
       "451              0.63                    22                     23   \n",
       "\n",
       "     Light_sleep_percentage  Awakenings  Caffeine_consumption  \\\n",
       "0                        12         0.0                   0.0   \n",
       "1                        53         3.0                   0.0   \n",
       "2                        10         1.0                   0.0   \n",
       "3                        52         3.0                  50.0   \n",
       "4                        18         3.0                   0.0   \n",
       "..                      ...         ...                   ...   \n",
       "445                      52         4.0                  50.0   \n",
       "447                      21         0.0                   0.0   \n",
       "448                      15         4.0                  25.0   \n",
       "450                      10         3.0                   0.0   \n",
       "451                      55         1.0                  50.0   \n",
       "\n",
       "     Alcohol_consumption Smoking_status  Exercise_frequency  \n",
       "0                    0.0            Yes                 3.0  \n",
       "1                    3.0            Yes                 3.0  \n",
       "2                    0.0             No                 3.0  \n",
       "3                    5.0            Yes                 1.0  \n",
       "4                    3.0             No                 3.0  \n",
       "..                   ...            ...                 ...  \n",
       "445                  2.0            Yes                 1.0  \n",
       "447                  0.0             No                 5.0  \n",
       "448                  0.0             No                 3.0  \n",
       "450                  0.0             No                 3.0  \n",
       "451                  0.0             No                 1.0  \n",
       "\n",
       "[388 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sleep_duration</th>\n",
       "      <th>Sleep_efficiency</th>\n",
       "      <th>REM_sleep_percentage</th>\n",
       "      <th>Deep_sleep_percentage</th>\n",
       "      <th>Light_sleep_percentage</th>\n",
       "      <th>Awakenings</th>\n",
       "      <th>Caffeine_consumption</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Exercise_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.63</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  Sleep_duration   Sleep_efficiency  REM_sleep_percentage  \\\n",
       "0     65  Female              6.0              0.88                    18   \n",
       "1     69    Male              7.0              0.66                    19   \n",
       "2     40  Female              8.0              0.89                    20   \n",
       "3     40  Female              6.0              0.51                    23   \n",
       "4     57    Male              8.0              0.76                    27   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "445   30  Female              7.5              0.53                    28   \n",
       "447   27  Female              7.5              0.91                    22   \n",
       "448   52    Male              6.0              0.74                    28   \n",
       "450   45    Male              7.0              0.76                    18   \n",
       "451   18    Male              7.5              0.63                    22   \n",
       "\n",
       "     Deep_sleep_percentage  Light_sleep_percentage  Awakenings  \\\n",
       "0                       70                      12         0.0   \n",
       "1                       28                      53         3.0   \n",
       "2                       70                      10         1.0   \n",
       "3                       25                      52         3.0   \n",
       "4                       55                      18         3.0   \n",
       "..                     ...                     ...         ...   \n",
       "445                     20                      52         4.0   \n",
       "447                     57                      21         0.0   \n",
       "448                     57                      15         4.0   \n",
       "450                     72                      10         3.0   \n",
       "451                     23                      55         1.0   \n",
       "\n",
       "     Caffeine_consumption  Alcohol_consumption Smoking_status  \\\n",
       "0                     0.0                  0.0            Yes   \n",
       "1                     0.0                  3.0            Yes   \n",
       "2                     0.0                  0.0             No   \n",
       "3                    50.0                  5.0            Yes   \n",
       "4                     0.0                  3.0             No   \n",
       "..                    ...                  ...            ...   \n",
       "445                  50.0                  2.0            Yes   \n",
       "447                   0.0                  0.0             No   \n",
       "448                  25.0                  0.0             No   \n",
       "450                   0.0                  0.0             No   \n",
       "451                  50.0                  0.0             No   \n",
       "\n",
       "     Exercise_frequency  \n",
       "0                   3.0  \n",
       "1                   3.0  \n",
       "2                   3.0  \n",
       "3                   1.0  \n",
       "4                   3.0  \n",
       "..                  ...  \n",
       "445                 1.0  \n",
       "447                 5.0  \n",
       "448                 3.0  \n",
       "450                 3.0  \n",
       "451                 1.0  \n",
       "\n",
       "[388 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Sleep_Efficiency.csv')\n",
    "dataset.rename(columns = {'Wakeup time':'Wakeup_time', 'Sleep duration (hrs)':'Sleep_duration ',\"Sleep efficiency (%)\":\"Sleep_efficiency\",\n",
    "                     \"REM sleep percentage\":\"REM_sleep_percentage\",\"Deep sleep percentage\":\"Deep_sleep_percentage\",\n",
    "                     \"Light sleep percentage\":\"Light_sleep_percentage\",\"Caffeine consumption (ml)\":\"Caffeine_consumption\",\n",
    "                     \"Alcohol consumption (days per week)\":\"Alcohol_consumption\",\"Smoking status\":\"Smoking_status\",\"Exercise frequency (days per week)\":\"Exercise_frequency\"}, inplace = True)\n",
    "#display(dataset)\n",
    "dataset = dataset.dropna()\n",
    "display(dataset)\n",
    "dataset.drop(dataset.columns[[0,3,4]], axis=1, inplace=True)\n",
    "\n",
    "display(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sleep_duration</th>\n",
       "      <th>Sleep_efficiency</th>\n",
       "      <th>REM_sleep_percentage</th>\n",
       "      <th>Deep_sleep_percentage</th>\n",
       "      <th>Light_sleep_percentage</th>\n",
       "      <th>Awakenings</th>\n",
       "      <th>Caffeine_consumption</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Exercise_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.63</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  Sleep_duration   Sleep_efficiency  REM_sleep_percentage  \\\n",
       "0     65  Female              6.0              0.88                    18   \n",
       "1     69    Male              7.0              0.66                    19   \n",
       "2     40  Female              8.0              0.89                    20   \n",
       "3     40  Female              6.0              0.51                    23   \n",
       "4     57    Male              8.0              0.76                    27   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "445   30  Female              7.5              0.53                    28   \n",
       "447   27  Female              7.5              0.91                    22   \n",
       "448   52    Male              6.0              0.74                    28   \n",
       "450   45    Male              7.0              0.76                    18   \n",
       "451   18    Male              7.5              0.63                    22   \n",
       "\n",
       "     Deep_sleep_percentage  Light_sleep_percentage  Awakenings  \\\n",
       "0                       70                      12         0.0   \n",
       "1                       28                      53         3.0   \n",
       "2                       70                      10         1.0   \n",
       "3                       25                      52         3.0   \n",
       "4                       55                      18         3.0   \n",
       "..                     ...                     ...         ...   \n",
       "445                     20                      52         4.0   \n",
       "447                     57                      21         0.0   \n",
       "448                     57                      15         4.0   \n",
       "450                     72                      10         3.0   \n",
       "451                     23                      55         1.0   \n",
       "\n",
       "     Caffeine_consumption  Alcohol_consumption Smoking_status  \\\n",
       "0                     0.0                  0.0            Yes   \n",
       "1                     0.0                  3.0            Yes   \n",
       "2                     0.0                  0.0             No   \n",
       "3                    50.0                  5.0            Yes   \n",
       "4                     0.0                  3.0             No   \n",
       "..                    ...                  ...            ...   \n",
       "445                  50.0                  2.0            Yes   \n",
       "447                   0.0                  0.0             No   \n",
       "448                  25.0                  0.0             No   \n",
       "450                   0.0                  0.0             No   \n",
       "451                  50.0                  0.0             No   \n",
       "\n",
       "     Exercise_frequency  \n",
       "0                   3.0  \n",
       "1                   3.0  \n",
       "2                   3.0  \n",
       "3                   1.0  \n",
       "4                   3.0  \n",
       "..                  ...  \n",
       "445                 1.0  \n",
       "447                 5.0  \n",
       "448                 3.0  \n",
       "450                 3.0  \n",
       "451                 1.0  \n",
       "\n",
       "[388 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = dataset.dropna()\n",
    "\n",
    "display(df.shape)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cols = list(df.columns.values) #Make a list of all of the columns in the df\\ncols.pop(cols.index('Sleep_efficiency')) #Remove b from list\\n#cols.pop(cols.index('x')) #Remove x from list\\ndf = df[cols+['Sleep_efficiency']] #Create new dataframe with columns in the order you want\\ndisplay(df)\\n\""
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cols = list(df.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('Sleep_efficiency')) #Remove b from list\n",
    "#cols.pop(cols.index('x')) #Remove x from list\n",
    "df = df[cols+['Sleep_efficiency']] #Create new dataframe with columns in the order you want\n",
    "display(df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sleep_duration</th>\n",
       "      <th>Sleep_efficiency</th>\n",
       "      <th>REM_sleep_percentage</th>\n",
       "      <th>Deep_sleep_percentage</th>\n",
       "      <th>Light_sleep_percentage</th>\n",
       "      <th>Awakenings</th>\n",
       "      <th>Caffeine_consumption</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Exercise_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.63</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  Sleep_duration   Sleep_efficiency  REM_sleep_percentage  \\\n",
       "0     65       1              6.0              0.88                    18   \n",
       "1     69       0              7.0              0.66                    19   \n",
       "2     40       1              8.0              0.89                    20   \n",
       "3     40       1              6.0              0.51                    23   \n",
       "4     57       0              8.0              0.76                    27   \n",
       "..   ...     ...              ...               ...                   ...   \n",
       "445   30       1              7.5              0.53                    28   \n",
       "447   27       1              7.5              0.91                    22   \n",
       "448   52       0              6.0              0.74                    28   \n",
       "450   45       0              7.0              0.76                    18   \n",
       "451   18       0              7.5              0.63                    22   \n",
       "\n",
       "     Deep_sleep_percentage  Light_sleep_percentage  Awakenings  \\\n",
       "0                       70                      12         0.0   \n",
       "1                       28                      53         3.0   \n",
       "2                       70                      10         1.0   \n",
       "3                       25                      52         3.0   \n",
       "4                       55                      18         3.0   \n",
       "..                     ...                     ...         ...   \n",
       "445                     20                      52         4.0   \n",
       "447                     57                      21         0.0   \n",
       "448                     57                      15         4.0   \n",
       "450                     72                      10         3.0   \n",
       "451                     23                      55         1.0   \n",
       "\n",
       "     Caffeine_consumption  Alcohol_consumption  Smoking_status  \\\n",
       "0                     0.0                  0.0               1   \n",
       "1                     0.0                  3.0               1   \n",
       "2                     0.0                  0.0               0   \n",
       "3                    50.0                  5.0               1   \n",
       "4                     0.0                  3.0               0   \n",
       "..                    ...                  ...             ...   \n",
       "445                  50.0                  2.0               1   \n",
       "447                   0.0                  0.0               0   \n",
       "448                  25.0                  0.0               0   \n",
       "450                   0.0                  0.0               0   \n",
       "451                  50.0                  0.0               0   \n",
       "\n",
       "     Exercise_frequency  \n",
       "0                   3.0  \n",
       "1                   3.0  \n",
       "2                   3.0  \n",
       "3                   1.0  \n",
       "4                   3.0  \n",
       "..                  ...  \n",
       "445                 1.0  \n",
       "447                 5.0  \n",
       "448                 3.0  \n",
       "450                 3.0  \n",
       "451                 1.0  \n",
       "\n",
       "[388 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapping = {'Male':0,'Female':1}\n",
    "df = df.replace({'Gender':mapping})\n",
    "\n",
    "mapping = {\"Yes\":1,'No':0}\n",
    "df = df.replace({'Smoking_status':mapping})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Gender', 'Sleep_duration ', 'Sleep_efficiency', 'Deep_sleep_percentage', 'Light_sleep_percentage', 'Awakenings', 'Caffeine_consumption', 'Alcohol_consumption', 'Smoking_status', 'Exercise_frequency']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "TargetVariable=['Caffeiene_consumption']\n",
    "column_names = list(df.columns.values)\n",
    "Predictors=[]\n",
    "#print(column_names)\n",
    "for i in column_names:\n",
    "    if (i!='Caffeiene_consumption'):\n",
    "        Predictors.append(i)\n",
    "\n",
    "print(Predictors) #all columns except Caffeiene_consumption\n",
    "print(len(Predictors)) #11\n",
    "\n",
    "X = df[Predictors].values\n",
    "y = df[TargetVariable].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler() #z-score\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "\n",
    "# Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X) #standardization\n",
    "y=TargetVarScalerFit.transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 11)\n",
      "(271, 1)\n",
      "(117, 11)\n",
      "(117, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.51.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.16.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 2ms/step - loss: 1.0275\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0260\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0250\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.0232\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.0204\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0154\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0080\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9960\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9794\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9546\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9227\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8821\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.8394\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7866\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7384\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6831\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6289\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5768\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5248\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4801\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4339\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3896\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3505\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3128\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2736\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2456\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2147\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1871\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1654\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1394\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1258\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1082\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0947\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0811\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0727\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0636\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0554\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0503\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0477\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0424\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0399\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0354\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0298\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0287\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0258\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0245\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0230\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c925ffbe0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# create ANN model\n",
    "model = Sequential()\n",
    " \n",
    "# Defining the Input layer and FIRST hidden layer, both are same!\n",
    "model.add(Dense(units=11, input_dim=11, kernel_initializer='normal', activation='relu')) #11 columns\n",
    " \n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model.add(Dense(units=11, kernel_initializer='normal', activation='tanh'))\n",
    " \n",
    "# The output neuron is a single fully connected node \n",
    "# Since we will be predicting a single number\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "# Compiling the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 20, epochs = 50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "1 Parameters: batch_size: 15 - epochs: 5 Accuracy: 96.16949537621224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "2 Parameters: batch_size: 15 - epochs: 10 Accuracy: 84.29736277116739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "3 Parameters: batch_size: 15 - epochs: 50 Accuracy: 82.92855617269527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4 Parameters: batch_size: 15 - epochs: 100 Accuracy: 90.79872141681943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "5 Parameters: batch_size: 20 - epochs: 5 Accuracy: 97.40861939061023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "6 Parameters: batch_size: 20 - epochs: 10 Accuracy: 100.21457982624494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "7 Parameters: batch_size: 20 - epochs: 50 Accuracy: 96.44768326490968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "8 Parameters: batch_size: 20 - epochs: 100 Accuracy: 89.04248972598347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\3708770948.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n"
     ]
    }
   ],
   "source": [
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list=[15, 20]\n",
    "    epoch_list  =   [5, 10, 50, 100]\n",
    "    \n",
    "    import pandas as pd\n",
    "    SearchResultsData=pd.DataFrame(columns=['Trial_no', 'Parameters', 'Accuracy'])\n",
    "    \n",
    "    # initializing the trials\n",
    "    TrialNumber=0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber+=1\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=11, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=11, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    " \n",
    "            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
    "            \n",
    "            # printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n",
    "            \n",
    "            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n",
    "                                                                    columns=['Trial_no', 'Parameters', 'Accuracy'] ))\n",
    "    return(SearchResultsData)\n",
    " \n",
    " \n",
    "######################################################\n",
    "# Calling the function\n",
    "ResultsData=FunctionFindBestParams(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Parameters'>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ResultsData.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sleep_duration</th>\n",
       "      <th>Sleep_efficiency</th>\n",
       "      <th>Deep_sleep_percentage</th>\n",
       "      <th>Light_sleep_percentage</th>\n",
       "      <th>Awakenings</th>\n",
       "      <th>Caffeine_consumption</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Exercise_frequency</th>\n",
       "      <th>REM_sleep_percentage</th>\n",
       "      <th>Predicted_REM_sleep_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.329788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.301653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.201321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.446926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.594667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Sleep_duration   Sleep_efficiency  Deep_sleep_percentage  \\\n",
       "0  25.0     0.0              7.0              0.86                   70.0   \n",
       "1  16.0     1.0              8.5              0.65                   35.0   \n",
       "2  52.0     0.0              7.0              0.83                   57.0   \n",
       "3  37.0     1.0              7.0              0.81                   55.0   \n",
       "4  58.0     0.0              8.0              0.87                   55.0   \n",
       "\n",
       "   Light_sleep_percentage    Awakenings  Caffeine_consumption  \\\n",
       "0                    10.0  1.000000e+00                  25.0   \n",
       "1                    47.0  2.000000e+00                   0.0   \n",
       "2                    20.0  1.000000e+00                   0.0   \n",
       "3                    20.0  1.000000e+00                   0.0   \n",
       "4                    18.0 -2.220446e-16                   0.0   \n",
       "\n",
       "   Alcohol_consumption  Smoking_status  Exercise_frequency  \\\n",
       "0                  0.0             0.0                 2.0   \n",
       "1                  0.0             0.0                 0.0   \n",
       "2                  0.0             1.0                 0.0   \n",
       "3                  5.0             0.0                 4.0   \n",
       "4                  3.0             1.0                 3.0   \n",
       "\n",
       "   REM_sleep_percentage  Predicted_REM_sleep_percentage  \n",
       "0                  20.0                       19.329788  \n",
       "1                  18.0                       18.301653  \n",
       "2                  23.0                       23.201321  \n",
       "3                  25.0                       25.446926  \n",
       "4                  27.0                       26.594667  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 20, epochs = 5, verbose=0)\n",
    " \n",
    "# Generating Predictions on testing data\n",
    "Predictions=model.predict(X_test)\n",
    "\n",
    "rounded_pred = np.argmax(Predictions,axis=1)\n",
    "display(rounded_pred)\n",
    " \n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n",
    " \n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    " \n",
    "# Scaling the test data back to original scale\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)\n",
    " \n",
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData['REM_sleep_percentage']=y_test_orig\n",
    "TestingData['Predicted_REM_sleep_percentage']=Predictions\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of ANN model is: 97.43759251894708\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Sleep_duration</th>\n",
       "      <th>Sleep_efficiency</th>\n",
       "      <th>Deep_sleep_percentage</th>\n",
       "      <th>Light_sleep_percentage</th>\n",
       "      <th>Awakenings</th>\n",
       "      <th>Caffeine_consumption</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Smoking_status</th>\n",
       "      <th>Exercise_frequency</th>\n",
       "      <th>REM_sleep_percentage</th>\n",
       "      <th>Predicted_REM_sleep_percentage</th>\n",
       "      <th>APE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.329788</td>\n",
       "      <td>3.351059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.301653</td>\n",
       "      <td>1.675849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.201321</td>\n",
       "      <td>0.875307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.446926</td>\n",
       "      <td>1.787704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.594667</td>\n",
       "      <td>1.501232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Sleep_duration   Sleep_efficiency  Deep_sleep_percentage  \\\n",
       "0  25.0     0.0              7.0              0.86                   70.0   \n",
       "1  16.0     1.0              8.5              0.65                   35.0   \n",
       "2  52.0     0.0              7.0              0.83                   57.0   \n",
       "3  37.0     1.0              7.0              0.81                   55.0   \n",
       "4  58.0     0.0              8.0              0.87                   55.0   \n",
       "\n",
       "   Light_sleep_percentage    Awakenings  Caffeine_consumption  \\\n",
       "0                    10.0  1.000000e+00                  25.0   \n",
       "1                    47.0  2.000000e+00                   0.0   \n",
       "2                    20.0  1.000000e+00                   0.0   \n",
       "3                    20.0  1.000000e+00                   0.0   \n",
       "4                    18.0 -2.220446e-16                   0.0   \n",
       "\n",
       "   Alcohol_consumption  Smoking_status  Exercise_frequency  \\\n",
       "0                  0.0             0.0                 2.0   \n",
       "1                  0.0             0.0                 0.0   \n",
       "2                  0.0             1.0                 0.0   \n",
       "3                  5.0             0.0                 4.0   \n",
       "4                  3.0             1.0                 3.0   \n",
       "\n",
       "   REM_sleep_percentage  Predicted_REM_sleep_percentage       APE  \n",
       "0                  20.0                       19.329788  3.351059  \n",
       "1                  18.0                       18.301653  1.675849  \n",
       "2                  23.0                       23.201321  0.875307  \n",
       "3                  25.0                       25.446926  1.787704  \n",
       "4                  27.0                       26.594667  1.501232  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APE=100*(abs(TestingData['REM_sleep_percentage']-TestingData['Predicted_REM_sleep_percentage'])/TestingData['REM_sleep_percentage'])\n",
    "TestingData['APE']=APE\n",
    " \n",
    "print('The Accuracy of ANN model is:', 100-np.mean(APE))\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_prsp = df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_12224\\1384300545.py:23: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  RegModel=KerasRegressor(make_regression_ann, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 2ms/step - loss: 0.9676\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9662\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9640\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9576\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9427\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9176\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8778\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8350\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7907\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7276\n",
      "###################################################################### Accuracy: 95.031973308206\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 1s 2ms/step - loss: 1.0072\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0064\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0044\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0008\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9914\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9738\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9425\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8915\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8305\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7763\n",
      "###################################################################### Accuracy: 77.71803657072198\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 1s 2ms/step - loss: 1.0231\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0212\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0189\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0132\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.0016\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9777\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9393\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8924\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8333\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7714\n",
      "###################################################################### Accuracy: 119.26465604929426\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 1.0328\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0311\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0288\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0255\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0153\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9983\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9703\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9331\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8951\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8489\n",
      "###################################################################### Accuracy: 75.76298258284916\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.9694\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9672\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9638\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9572\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9462\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9268\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9007\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8690\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8290\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7832\n",
      "###################################################################### Accuracy: 79.64849598717873\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 2ms/step - loss: 0.9676\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9662\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9644\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9614\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9562\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9457\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9276\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9013\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8700\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8327\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7928\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.7540\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7051\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6562\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6093\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5529\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4969\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4382\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3754\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3227\n",
      "###################################################################### Accuracy: 51.964918240379035\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 5ms/step - loss: 1.0077\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0056\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 1.0023\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.9957\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9844\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9608\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9257\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8751\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8088\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7379\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6502\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5758\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4934\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.4278\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.3644\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3100\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2726\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2319\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1952\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.1703\n",
      "###################################################################### Accuracy: 48.389179334394896\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 2ms/step - loss: 1.0235\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0220\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0193\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.0116\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9909\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9512\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8918\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8148\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7445\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6789\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5958\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5325\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4701\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4180\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3701\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3126\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2746\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2409\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2088\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1766\n",
      "###################################################################### Accuracy: 93.96434333405135\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 1.0324\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0306\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0285\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0239\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0152\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0022\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9788\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9469\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9146\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8759\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8260\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7696\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7075\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6430\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5879\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5383\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4787\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4233\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3882\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3397\n",
      "###################################################################### Accuracy: 70.37933958072493\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.9695\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9684\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9673\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9652\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9609\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9526\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9376\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9147\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8825\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8380\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7825\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7193\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6496\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5831\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5197\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4553\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4045\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3431\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2932\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2569\n",
      "###################################################################### Accuracy: 91.18635897057925\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 0.9678\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9668\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9659\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9647\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9627\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9588\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9522\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9435\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9270\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9072\n",
      "###################################################################### Accuracy: 103.54666546044736\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 3ms/step - loss: 1.0071\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0065\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0062\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0056\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0045\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0025\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9988\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9917\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9797\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9613\n",
      "###################################################################### Accuracy: 96.31482539044343\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 1.0235\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0224\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0217\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0205\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0177\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0133\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0052\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9923\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9727\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9451\n",
      "###################################################################### Accuracy: 126.99347620308703\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 1.0328\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0316\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0305\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0287\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0253\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0194\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0093\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9960\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9770\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9528\n",
      "###################################################################### Accuracy: 90.95475373020867\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 0.9698\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9690\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9685\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9680\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9670\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9659\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9633\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9594\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9538\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9440\n",
      "###################################################################### Accuracy: 83.66183272890504\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 0.9679\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9666\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9657\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9646\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9623\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9591\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9543\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9462\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9359\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9213\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9036\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8848\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8570\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8286\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8001\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7684\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7337\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6957\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6671\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6145\n",
      "###################################################################### Accuracy: 74.70348635403825\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 1.0063\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0047\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0031\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9998\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9955\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9880\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9760\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9579\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9341\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9029\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8696\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8299\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7860\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7388\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6925\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6461\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5981\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5561\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5108\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4722\n",
      "###################################################################### Accuracy: 65.49901652870601\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 1.0233\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0222\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0205\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0174\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0122\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0029\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9887\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9656\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9396\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8983\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8590\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8146\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7709\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7298\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6875\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6462\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6113\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5763\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5398\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5049\n",
      "###################################################################### Accuracy: 111.34522852225594\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 1.0335\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0311\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0297\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0269\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0217\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0148\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0029\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9861\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9689\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9406\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9093\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8757\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8366\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7946\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7477\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6961\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6450\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5879\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5340\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4826\n",
      "###################################################################### Accuracy: 78.03496149899992\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 3ms/step - loss: 0.9699\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9688\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9678\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9664\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9641\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9605\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9547\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9456\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9314\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9129\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8909\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8574\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8209\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7787\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7358\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6917\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6480\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5981\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5487\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5042\n",
      "###################################################################### Accuracy: 83.94732361589564\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 0.9678\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9669\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9662\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9653\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9639\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9621\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9589\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9545\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9485\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9395\n",
      "###################################################################### Accuracy: 108.25456725155883\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 1.0069\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0060\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0050\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0040\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0025\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0005\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9972\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9925\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9857\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9769\n",
      "###################################################################### Accuracy: 93.1649818688355\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 4ms/step - loss: 1.0229\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0216\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0203\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0182\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0147\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0092\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0001\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9882\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9721\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9516\n",
      "###################################################################### Accuracy: 119.56738054520957\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.0325\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0316\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0307\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0298\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0273\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0240\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0187\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0110\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9995\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9837\n",
      "###################################################################### Accuracy: 94.10220786684269\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.9691\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9680\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9665\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9650\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9624\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9593\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9543\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9480\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9399\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9303\n",
      "###################################################################### Accuracy: 80.68479258978353\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.9678\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9672\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9668\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9662\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9655\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9643\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9625\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9589\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9535\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9459\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9358\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9226\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9083\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8919\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8748\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8577\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8397\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8196\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7953\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7718\n",
      "###################################################################### Accuracy: 95.76177138594436\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.0069\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0061\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0054\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0044\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0031\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0011\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9981\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9937\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9875\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9811\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9704\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9584\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9445\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9289\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9124\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8963\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8793\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8615\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8449\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8264\n",
      "###################################################################### Accuracy: 67.53821217191945\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.0233\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0222\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0213\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0200\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0184\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0159\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0119\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0073\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0002\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9914\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9776\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9624\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9441\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9239\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8980\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8738\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8478\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8220\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7943\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7654\n",
      "###################################################################### Accuracy: 120.9286609396774\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.0325\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0320\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0313\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0300\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0279\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0246\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0193\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0105\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9984\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9809\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9592\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9329\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9021\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8692\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8329\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7947\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7586\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7238\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6872\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6483\n",
      "###################################################################### Accuracy: 76.49158260213909\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.9698\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9689\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9681\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9673\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9662\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9646\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9620\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9583\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9528\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9455\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9347\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9198\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9031\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8812\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8589\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8320\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8022\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7722\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7428\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7073\n",
      "###################################################################### Accuracy: 77.71876746312142\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9679\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9667\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9649\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9621\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9575\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9514\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9437\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9342\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9218\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9080\n",
      "###################################################################### Accuracy: 115.48362860829081\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0071\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0058\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0027\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9975\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9891\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9782\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9622\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9418\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9201\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8959\n",
      "###################################################################### Accuracy: 85.50716640387722\n",
      "Epoch 1/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0243\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0228\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0212\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0170\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0088\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9952\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9760\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9507\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9210\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8916\n",
      "###################################################################### Accuracy: 119.83658586165834\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0325\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0303\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0286\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.0263\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0219\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0158\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0080\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9975\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9840\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9689\n",
      "###################################################################### Accuracy: 98.86988495972571\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9700\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9683\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9640\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9597\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9539\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9445\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9346\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9220\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9050\n",
      "###################################################################### Accuracy: 84.40475319346098\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9679\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9667\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9647\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9612\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9551\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9470\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9364\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9253\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9104\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8922\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8725\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8515\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8281\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8012\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.7729\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7402\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7089\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6721\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6336\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5967\n",
      "###################################################################### Accuracy: 76.13124597629994\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0074\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0066\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0054\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0041\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0021\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9987\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9937\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9860\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9756\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9632\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.9489\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9297\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.9087\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8835\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.8547\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8220\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7937\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7626\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.7289\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6937\n",
      "###################################################################### Accuracy: 85.47235553986178\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0233\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0210\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0174\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.0111\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 1.0020\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9888\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9709\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9467\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.9219\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8949\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8691\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8436\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.8183\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7920\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7652\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.7379\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7073\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6811\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.6481\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6194\n",
      "###################################################################### Accuracy: 104.99704767036364\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0329\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0319\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0306\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0284\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0243\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0190\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0120\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0012\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9909\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9782\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9642\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9489\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9313\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9123\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8974\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8811\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8634\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8441\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8252\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8046\n",
      "###################################################################### Accuracy: 81.27968215049115\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.9693\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9671\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9650\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9611\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9562\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9482\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9385\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9236\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9055\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8827\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8543\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8242\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7884\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7530\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7139\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6734\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6304\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5839\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5416\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4989\n",
      "###################################################################### Accuracy: 81.42129271824722\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 2ms/step - loss: 0.9678\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9668\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9659\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9645\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9627\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9598\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9563\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9511\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9440\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9355\n",
      "###################################################################### Accuracy: 109.56251805147032\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 3ms/step - loss: 1.0064\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0044\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0024\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9993\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9956\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9903\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9834\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9751\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9655\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9552\n",
      "###################################################################### Accuracy: 87.13535659990362\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 1s 3ms/step - loss: 1.0241\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0227\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0213\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0193\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0162\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0120\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0054\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9973\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9861\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9726\n",
      "###################################################################### Accuracy: 120.39164890691129\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0325\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0313\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0301\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0282\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0259\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0223\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0175\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0113\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0041\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9950\n",
      "###################################################################### Accuracy: 103.13890251245743\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9702\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9691\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9679\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9667\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9645\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9617\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9574\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9514\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9440\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9349\n",
      "###################################################################### Accuracy: 86.54519188896508\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9677\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9670\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9662\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9646\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9624\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9596\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9551\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9489\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9411\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9320\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9208\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9074\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8925\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8759\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8571\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8377\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8159\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7975\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7747\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7547\n",
      "###################################################################### Accuracy: 85.33758790792604\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0071\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0063\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0053\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0039\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0021\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9998\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9959\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9912\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9851\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9782\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9705\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9607\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9505\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9389\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9254\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9130\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8984\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8835\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8680\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8525\n",
      "###################################################################### Accuracy: 85.62002986832665\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0235\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0224\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0219\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0204\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0184\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0156\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0107\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0040\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9960\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9854\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9725\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9576\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9413\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9234\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9070\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8879\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8711\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8518\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8324\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8131\n",
      "###################################################################### Accuracy: 122.9089878437006\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0325\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0313\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0301\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.0256\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0217\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0169\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0115\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0045\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9964\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9877\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9774\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9643\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9505\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9349\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9181\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9007\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8847\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8667\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8479\n",
      "###################################################################### Accuracy: 77.20066786790252\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9697\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9689\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9682\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9679\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9666\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9649\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.9622\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9583\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9532\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9466\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9391\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9300\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9192\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9078\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8948\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8806\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8658\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8504\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8320\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8140\n",
      "###################################################################### Accuracy: 73.05451434272427\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9675\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9664\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9658\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9644\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9628\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9607\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9581\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9545\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9509\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9456\n",
      "###################################################################### Accuracy: 108.71298034925266\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0072\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0064\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0058\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0048\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0034\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0014\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9990\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9955\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9919\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9869\n",
      "###################################################################### Accuracy: 102.28164492677537\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0226\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0207\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0182\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0149\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0117\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0070\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0017\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9945\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9860\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9761\n",
      "###################################################################### Accuracy: 133.71197284348347\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 1.0324\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0315\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0307\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0293\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0276\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0252\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0226\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0185\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0141\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0082\n",
      "###################################################################### Accuracy: 96.48185111462331\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9698\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9688\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9682\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9674\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9664\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9650\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9631\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9606\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9573\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9536\n",
      "###################################################################### Accuracy: 86.45263964224513\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9677\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9664\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9653\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9639\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9616\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9598\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9560\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9525\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9485\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9430\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9368\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9295\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9218\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9116\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9031\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8923\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8827\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8710\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8597\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8462\n",
      "###################################################################### Accuracy: 90.7847127871676\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0071\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0064\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0060\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0053\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0043\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0032\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0018\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9996\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9968\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9935\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9891\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9841\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9784\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9713\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9635\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9550\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9452\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9363\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9245\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9134\n",
      "###################################################################### Accuracy: 94.80821800915807\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0233\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0222\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0212\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0197\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0177\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0145\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0099\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0045\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9975\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9891\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9794\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9682\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9553\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9409\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9255\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9099\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8920\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8751\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8563\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8396\n",
      "###################################################################### Accuracy: 118.05599986629994\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0325\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0314\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0302\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0286\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0259\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0219\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0172\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0105\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.0032\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9946\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9848\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9755\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9643\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9523\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9395\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9267\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9124\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8987\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8841\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8695\n",
      "###################################################################### Accuracy: 68.41234732735961\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9701\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9694\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9686\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9677\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9666\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9651\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9627\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9599\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9563\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9519\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9463\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9397\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9321\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9219\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9113\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9002\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8873\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8744\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8606\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8453\n",
      "###################################################################### Accuracy: 78.82439498727769\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9992\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9969\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9940\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.9899\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9845\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9774\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9686\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9582\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9468\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9344\n",
      "########## Total Time Taken:  2 Minutes\n",
      "### Printing Best parameters ###\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Optimizer_trial': 'rmsprop', 'batch_size': 30, 'epochs': 10}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_regression_ann(Optimizer_trial):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=11, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=11, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Optimizer_trial)\n",
    "    return model\n",
    " \n",
    "###########################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    " \n",
    "# Listing all the parameters to try\n",
    "Parameter_Trials={'batch_size':[10,20,30],\n",
    "                      'epochs':[10,20],\n",
    "                    'Optimizer_trial':['adam', 'rmsprop']\n",
    "                 }\n",
    " \n",
    "# Creating the regression ANN model\n",
    "RegModel=KerasRegressor(make_regression_ann, verbose=0)\n",
    " \n",
    "###########################################\n",
    "from sklearn.metrics import make_scorer\n",
    " \n",
    "# Defining a custom function to calculate accuracy\n",
    "def Accuracy_Score(orig,pred):\n",
    "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
    "    print('#'*70,'Accuracy:', 100-MAPE)\n",
    "    return(100-MAPE)\n",
    " \n",
    "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
    " \n",
    "#########################################\n",
    "# Creating the Grid search space\n",
    "# See different scoring methods by using sklearn.metrics.SCORERS.keys()\n",
    "grid_search=GridSearchCV(estimator=RegModel, \n",
    "                         param_grid=Parameter_Trials, \n",
    "                         scoring=custom_Scoring, \n",
    "                         cv=5)\n",
    " \n",
    "#########################################\n",
    "# Measuring how much time it took to find the best params\n",
    "import time\n",
    "StartTime=time.time()\n",
    " \n",
    "# Running Grid Search for different paramenters\n",
    "grid_search.fit(X,y, verbose=1)\n",
    " \n",
    "EndTime=time.time()\n",
    "print(\"########## Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes')\n",
    " \n",
    "print('### Printing Best parameters ###')\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
